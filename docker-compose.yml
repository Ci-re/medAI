version: '3.8'

services:
  medassist-rag:
    build: .
    container_name: medassist-rag-chatbot
    ports:
      - "8501:8501"
    environment:
      # Application Configuration
      - APP_NAME=MedAssist AI RAG Production
      - APP_VERSION=1.0.0
      - DATABASE_URL=data/conversations.db
      - VECTOR_DB_PATH=data/vector_store
      - LOG_LEVEL=INFO
      
      # API Configuration
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=gemini-1.5-flash
      - MAX_TOKENS=1500
      - TEMPERATURE=0.3
      
      # RAG Configuration
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - TOP_K_RETRIEVAL=5
      - SIMILARITY_THRESHOLD=0.7
      - CHUNK_SIZE=500
      - CHUNK_OVERLAP=50
      
      # Rate Limiting
      - MAX_CONVERSATION_LENGTH=50
      - RATE_LIMIT_REQUESTS=100
      - RATE_LIMIT_WINDOW=3600
    
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  default:
    driver: bridge

